{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with Human Resource Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore analyzing a Human Resource analytics data set and create a neural network to predict whether an employee will leave or stay based on certain features we are given. We will be using the Tensorflow, numpy and pandas python libraries to achieve this goal. The original data set can be found [here](https://www.kaggle.com/ludobenistant/hr-analytics). The original python script is setup to accept command line flags to try different techniques I worked through this data with. If you are interested in seeing the results of full batch versus mini-batch training or Recitified Linear Unit(Relu) versus Exponential Linear Unit(Elu) activation functions then you can try it [BROKEN LINK]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.5.2 64bit [GCC 5.4.0 20160609]"
        },
        {
         "module": "IPython",
         "version": "5.1.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.4.0 62 generic x86_64 with Ubuntu 16.04 xenial"
        },
        {
         "module": "tensorflow",
         "version": "0.12.1"
        },
        {
         "module": "numpy",
         "version": "1.12.0"
        },
        {
         "module": "pandas",
         "version": "0.19.2"
        },
        {
         "module": "matplotlib",
         "version": "1.5.3"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.5.2 64bit [GCC 5.4.0 20160609]</td></tr><tr><td>IPython</td><td>5.1.0</td></tr><tr><td>OS</td><td>Linux 4.4.0 62 generic x86_64 with Ubuntu 16.04 xenial</td></tr><tr><td>tensorflow</td><td>0.12.1</td></tr><tr><td>numpy</td><td>1.12.0</td></tr><tr><td>pandas</td><td>0.19.2</td></tr><tr><td>matplotlib</td><td>1.5.3</td></tr><tr><td colspan='2'>Wed Feb 15 20:44:46 2017 CST</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.5.2 64bit [GCC 5.4.0 20160609] \\\\ \\hline\n",
       "IPython & 5.1.0 \\\\ \\hline\n",
       "OS & Linux 4.4.0 62 generic x86\\_64 with Ubuntu 16.04 xenial \\\\ \\hline\n",
       "tensorflow & 0.12.1 \\\\ \\hline\n",
       "numpy & 1.12.0 \\\\ \\hline\n",
       "pandas & 0.19.2 \\\\ \\hline\n",
       "matplotlib & 1.5.3 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Wed Feb 15 20:44:46 2017 CST} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.5.2 64bit [GCC 5.4.0 20160609]\n",
       "IPython 5.1.0\n",
       "OS Linux 4.4.0 62 generic x86_64 with Ubuntu 16.04 xenial\n",
       "tensorflow 0.12.1\n",
       "numpy 1.12.0\n",
       "pandas 0.19.2\n",
       "matplotlib 1.5.3\n",
       "Wed Feb 15 20:44:46 2017 CST"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using magic commands for set up and showing working versions\n",
    "%matplotlib inline\n",
    "%load_ext version_information\n",
    "%version_information tensorflow, numpy, pandas, matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set our seeds for the environment and pull in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "tf.set_random_seed(7)\n",
    "\n",
    "init_data = pd.read_csv(\"./HR_comma_sep.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at the data we are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      "satisfaction_level       14999 non-null float64\n",
      "last_evaluation          14999 non-null float64\n",
      "number_project           14999 non-null int64\n",
      "average_montly_hours     14999 non-null int64\n",
      "time_spend_company       14999 non-null int64\n",
      "Work_accident            14999 non-null int64\n",
      "left                     14999 non-null int64\n",
      "promotion_last_5years    14999 non-null int64\n",
      "sales                    14999 non-null object\n",
      "salary                   14999 non-null object\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(init_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have 10 columns of features, 2 of those are of type object, with no null values in the data. Next we need to look at what type of data is in the two columns with the type object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales: 0    sales\n",
      "1    sales\n",
      "2    sales\n",
      "3    sales\n",
      "4    sales\n",
      "Name: sales, dtype: object\n",
      "Salary: 0       low\n",
      "1    medium\n",
      "2    medium\n",
      "3       low\n",
      "4       low\n",
      "Name: salary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Sales: {0}\".format(init_data[\"sales\"][:5]))\n",
    "print(\"Salary: {0}\".format(init_data[\"salary\"][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance it looks like the column \"sales\" is holding nominal data and the column \"salary\" is holding ordinal data. Lets see how many unique values we have in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique sale categories: 10\n",
      "Unique salary categories: 3\n"
     ]
    }
   ],
   "source": [
    "sales_unique_n = init_data[\"sales\"].nunique()\n",
    "salary_unique_n = init_data[\"salary\"].nunique()\n",
    "print(\"Unique sale categories: {0}\".format(sales_unique_n))\n",
    "print(\"Unique salary categories: {0}\".format(salary_unique_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the nominal data has 10 categories and the ordinal data has 3 categories. Now we need to convert this data into something that our nerual network can work with. The way we are going to handle converting this data is by breaking these categories down into their own binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_unique_feature_names = init_data[\"sales\"].unique()\n",
    "salary_unique_feature_names = init_data[\"salary\"].unique()\n",
    "\n",
    "# Function to breakdown a category into individual binary features\n",
    "def break_down_features(feature_list, category, orig_data):\n",
    "    for name in feature_list:\n",
    "        orig_data[category+\"_\"+name] = [1 if x == name else 0 for _, x in enumerate(orig_data[category])]\n",
    "\n",
    "break_down_features(sales_unique_feature_names, \"sales\", init_data)\n",
    "break_down_features(salary_unique_feature_names, \"salary\", init_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have broken down the categories lets get rid of our original sales and salary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_data = init_data.drop([\"sales\", \"salary\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the feature we are wanting to predict is whether the employee has left or not, we should look at the percentages of left versus stayed in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.761917\n",
      "1    0.238083\n",
      "Name: left, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(init_data[\"left\"].value_counts() / len(init_data[\"left\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have about ~76% of people who stayed and ~24% of people who left. When we split our data into the training and test sets we want to try and maintain these percentages in our new distributions. Lets create a function that will do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stratified_split_data(data, ratio):\n",
    "    # Grab the data into its own category\n",
    "    stayed_data = data.loc[data[\"left\"] == 0]\n",
    "    left_data = data.loc[data[\"left\"] == 1]\n",
    "    # mix up the data\n",
    "    stayed_data = stayed_data.iloc[np.random.permutation(len(stayed_data))]\n",
    "    left_data = left_data.iloc[np.random.permutation(len(left_data))]\n",
    "    test_stayed_set_size = int(len(stayed_data) * ratio)\n",
    "    test_left_set_size = int(len(left_data) * ratio)\n",
    "    # Concatenate the partitioned data\n",
    "    train_set = pd.concat([stayed_data[test_stayed_set_size:], left_data[test_left_set_size:]], ignore_index=True)\n",
    "    test_set = pd.concat([stayed_data[:test_stayed_set_size], left_data[:test_left_set_size]], ignore_index=True)\n",
    "    # Now mix up the concatenated data\n",
    "    train_shuffled_indices = np.random.permutation(len(train_set))\n",
    "    test_shuffled_indices = np.random.permutation(len(test_set))\n",
    "    return train_set.iloc[train_shuffled_indices], test_set.iloc[test_shuffled_indices]\n",
    "\n",
    "train_set, test_set = stratified_split_data(init_data, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our stratified samples. However, just to make sure, we can look at our training set percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.761917\n",
      "1    0.238083\n",
      "Name: left, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_set[\"left\"].value_counts() / len(train_set[\"left\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems our sample size's percentages match perfectly. So now lets split out our training set into the data and the data labels. Also lets grab the number of features we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = (train_set.drop(\"left\", axis=1)).values\n",
    "data_labels = train_set[\"left\"].values\n",
    "data_labels = data_labels.reshape([len(data_labels), 1])\n",
    "num_features = data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets start defining our model. The model we will create will have 2 hidden layers and an output layer. Lets start with defining the inputs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_init = tf.placeholder(tf.float32, [None, num_features])\n",
    "Y_init = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create our first hidden layer. Typically your hidden layers will use a Rectified Linear Unit(Relu) activation function in these cases, but in our case we will use an Exponential Linear Unit(Elu) activation function for its nice properties of reducing the bias shift effect on our network to have faster learning than Relu and for the fact that it acts like batch normalization without the computational complexity. We will also add the caveat of initalizing our weights and biases with a standard deviation of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_1 = tf.Variable(tf.truncated_normal([num_features, 10], stddev=0.01))\n",
    "b_1 = tf.Variable(tf.truncated_normal([10], stddev=0.01))\n",
    "\n",
    "layer_1 = tf.nn.elu(tf.add(tf.matmul(X_init, w_1), b_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second hidden layer will be the same but adjusted for the new input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_2 = tf.Variable(tf.truncated_normal([10, 8], stddev=0.01))\n",
    "b_2 = tf.Variable(tf.truncated_normal([8], stddev=0.01))\n",
    "\n",
    "layer_2 = tf.nn.elu(tf.add(tf.matmul(layer_1, w_2), b_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for our final output layer we will use the sigmoid function for our activation function because we want our output to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_3 = tf.Variable(tf.truncated_normal([8, 1], stddev=0.01))\n",
    "b_3 = tf.Variable(tf.truncated_normal([1], stddev=0.01))\n",
    "\n",
    "output_layer = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, w_3), b_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will define our cost function, which will be the cross entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(tf.multiply(Y_init, tf.log(output_layer)) + (1 - Y_init)*tf.log(1 - output_layer) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our optimizer we will use Adam with a learning rate of 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(1e-3).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do some tensorflow setup and define an array to store our loss function values when we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "loss_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have played around with the values and have found decent numbers to use for our epoch and batch size in our model. We will use 600 epochs and a batch size of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 600\n",
    "batch_size = 50\n",
    "count = len(data) # helper variable for our mini-batch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets set up our training and then print out our final cost value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cost = 0.10991400480270386\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    start_n = 0\n",
    "    c = None\n",
    "    while start_n < count:\n",
    "        sess.run(optimizer, feed_dict={X_init:data[start_n:(start_n + batch_size)], Y_init:data_labels[start_n:(start_n + batch_size)]})\n",
    "        start_n += batch_size\n",
    "    c = sess.run(cost, feed_dict={X_init:data, Y_init:data_labels})\n",
    "    loss_values.append(c)\n",
    "print(\"Final cost = {0}\".format(sess.run(cost, feed_dict={X_init:data, Y_init:data_labels})) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the loss function looks like graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFkCAYAAACjCwibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3XuYXXV97/H3N8mQKxlI0iTEILcESCkiGSkGqVBQEBVa\nDz7oKEdPETUtPY+mXipY5RQvrfYR6g0vvXCRMpVjLXLOoSJgrRUIlxlArYBKQOSSQAIMIQlkJvmd\nP357zJ7JXPbe2TNr7z3v1/OsZ+299lprf/cvk9mf+a3fWitSSkiSJI1lStEFSJKk5mBokCRJFTE0\nSJKkihgaJElSRQwNkiSpIoYGSZJUEUODJEmqiKFBkiRVxNAgSZIqYmiQJEkVqSk0RMR5EfFQRGyL\niLURccwY67dHxJcj4vHSNvdHxOtqK1mSJBVhWrUbRMRbgM8B7wHuANYAN0TEoSmljcOs3wbcBKwH\n/hvwOHAA8Owe1C1JkiZYVHvDqohYC9yeUnpf6XkAvwa+kFL67DDrrwY+AByeUtqx5yVLkqQiVHV4\notRr0AHcPLAs5dRxE7BqhM1OB24DLo2I9RHxk4g4PyIcTyFJUhOp9vDEAmAqsGHI8g3AYSNsczBw\nEnAVcBqwHLi0tJ9PDrdBRMwHTgUeBl6oskZJkiazGcCBwA0ppU313HHVYxpGEMBIxzmmkEPFe0q9\nEndHxEuADzJCaCAHhn+qU22SJE1GbweurucOqw0NG4EdwKIhyxeye+/DgCeA7Wnw4In7gMURMS2l\n1D/MNg8DXHXVVaxYsaLKEievNWvWcMkllxRdRtOx3apnm9XGdquebVa9++67j7PPPhtK36X1VFVo\nSCn1RUQ3cDJwHfxmIOTJwBdG2OwWoHPIssOAJ0YIDFA6JLFixQpWrlxZTYmTWnt7u+1VA9uterZZ\nbWy36tlme6Tuh/drGYx4MfCeiHhHRBwOfBWYBVwOEBFXRsSny9b/CjA/Ij4fEcsj4g3A+cCX9qx0\nSZI0kaoe05BSuiYiFgAXkQ9T3AOcmlJ6qrTKUqC/bP1HI+IU4BLgXuCx0uPdTs+UJEmNq6aBkCml\nS8lnQAz32knDLLsdOK6W95IkSY3BayW0kM7OoUNHVAnbrXq2WW1st+rZZo2l6itCToSIWAl0d3d3\nOwBGkqQq9PT00NHRAdCRUuqp577taZAkSRUxNEiSpIoYGiRJUkUMDZIkqSKGBkmSVBFDgyRJqoih\nQZIkVcTQIEmSKmJokCRJFTE0SJKkihgaJElSRQwNkiSpIoYGSZJUEUODJEmqiKFBkiRVxNAgSZIq\nYmiQJEkVMTRIkqSKGBokSVJFDA2SJKkihgZJklQRQ4MkSaqIoUGSJFXE0CBJkipiaJAkSRUxNEiS\npIo0dGjo6yu6AkmSNMDQIEmSKmJokCRJFWno0NDfX3QFkiRpQEOHBnsaJElqHA0dGuxpkCSpcTR0\naLCnQZKkxtHQocGeBkmSGoehQZIkVcTQIEmSKtLQocExDZIkNY6GDg32NEiS1DgaOjTY0yBJUuNo\n6NBgT4MkSY2joUODPQ2SJDWOhg4N9jRIktQ4Gjo02NMgSVLjMDRIkqSKNHRo8PCEJEmNo6FDgz0N\nkiQ1joYODfY0SJLUOAwNkiSpIoYGSZJUkZpCQ0ScFxEPRcS2iFgbEceMsu47I2JnROwozXdGxNZK\n3scxDZIkNY6qQ0NEvAX4HHAhcDRwL3BDRCwYZbNeYHHZdEAl72VPgyRJjaOWnoY1wNdSSlemlO4H\nVgNbgXNG2SallJ5KKT1Zmp6q5I3saZAkqXFUFRoiog3oAG4eWJZSSsBNwKpRNp0TEQ9HxCMRcW1E\n/HYl72dPgyRJjaPanoYFwFRgw5DlG8iHHYbzALkX4gzg7aX3vDUiXjLWm9nTIElS45hWp/0EkIZ7\nIaW0Flj7mxUjbgPuA95DHhcxottuW8MZZ7QPWtbZ2UlnZ+ee1itJUtPr6uqiq6tr0LLe3t5xe79q\nQ8NGYAewaMjyheze+zCslFJ/RNwNLBtr3Ze//BKuu25llSVKkjQ5DPeHdE9PDx0dHePyflUdnkgp\n9QHdwMkDyyIiSs9vrWQfETEF+B3gibHWdUyDJEmNo5bDExcDV0REN3AH+WyKWcDlABFxJfBoSumC\n0vOPkQ9P/BLYB/gw+ZTLvx/rjRzTIElS46g6NKSUrildk+Ei8mGKe4BTy06jXAqU9xHsC3ydPFDy\nGXJPxarS6ZqjsqdBkqTGUdNAyJTSpcClI7x20pDnfwb8WS3vY2iQJKlxeO8JSZJUkYYODY5pkCSp\ncTR0aNi+vegKJEnSgIYODVsruhemJEmaCA0dGp5/vugKJEnSgIYODVu2FF2BJEka0NChoa/PcQ2S\nJDWKhg4NAJs3F12BJEmCJggNzz1XdAWSJAkMDZIkqUINHxo8PCFJUmNo+NBgT4MkSY3B0CBJkipi\naJAkSRVp6NAwe7ZjGiRJahQNHxrsaZAkqTE0dGiYNQt6e4uuQpIkQYOHhn33hY0bi65CkiRBg4eG\nefNgw4aiq5AkSdDgoWH+fEODJEmNoqFDgz0NkiQ1joYODfPnw1NPQX9/0ZVIkqSGDw0pORhSkqRG\n0NChYd68PPcQhSRJxWvo0DB/fp4bGiRJKl7Dh4YIePTRoiuRJEkNHRqmT4cDDoAHHii6EkmS1NCh\nAeDww+G++4quQpIkNUVouP/+oquQJEkNHxpWrIB16+DFF4uuRJKkya3hQ8MRR8COHfCznxVdiSRJ\nk1vDh4aVK2HaNLjttqIrkSRpcmv40DBzJrz85YYGSZKK1vChAeC44wwNkiQVrSlCw6pV8OCD8OST\nRVciSdLk1TShAextkCSpSE0RGl76UthvP0ODJElFaorQEJF7GwwNkiQVpylCA+TBkHfeCX19RVci\nSdLk1DShYdUq2LYNfvzjoiuRJGlyaprQsHIltLXBrbcWXYkkSZNT04SGGTNycHBcgyRJxWia0ABe\n5EmSpCI1VWhYtQoefhjWry+6EkmSJp+mCw1gb4MkSUVoqtCwdGmeHAwpSdLEa6rQAI5rkCSpKE0X\nGlatgrvugu3bi65EkqTJpSlDw4svwj33FF2JJEmTS9OFhqOPhunTPUQhSdJEa7rQsNde8IpXOBhS\nkqSJVlNoiIjzIuKhiNgWEWsj4pgKt3trROyMiG/X8r4DOjq8B4UkSROt6tAQEW8BPgdcCBwN3Avc\nEBELxtjuAOBvgB/WUOcgy5fDunWwY8ee7kmSJFWqlp6GNcDXUkpXppTuB1YDW4FzRtogIqYAVwEf\nBx6qpdByy5blsycefXRP9yRJkipVVWiIiDagA7h5YFlKKQE3AatG2fRC4MmU0mW1FDnUsmV5/stf\n1mNvkiSpEtX2NCwApgIbhizfACweboOIeBXwR8C5VVc3ggMOgKlT4Re/qNceJUnSWKbVaT8BpN0W\nRswBvgG8O6X0TLU7XbNmDe3t7YOWdXZ20tnZyYEHwoMP1litJEktoKuri66urkHLent7x+39Ih9d\nqHDlfHhiK3BmSum6suWXA+0ppTcNWf8ooAfYQQ4WsKt3YwdwWEpptzEOEbES6O7u7mblypXD1nLi\nibBkCVx9dcXlS5LU8np6eujo6ADoSCn11HPfVR2eSCn1Ad3AyQPLIiJKz4e7csJ9wJHAy4GjStN1\nwPdLj39dU9XkwPD447VuLUmSqlXL4YmLgSsiohu4g3w2xSzgcoCIuBJ4NKV0QUppO/Cz8o0j4lny\n+Mn79qTwJUvyPSgkSdLEqDo0pJSuKV2T4SJgEXAPcGpK6anSKkuB/vqVOLyBnoaUIGLs9SVJ0p6p\naSBkSulS4NIRXjtpjG3/qJb3HGrJEtiyBTZvhrlz67FHSZI0mqa798SAJUvy3HENkiRNDEODJEmq\nSNOGhkWL8nzD0MtMSZKkcdG0oWHOHJgyBcbxGhaSJKlM04aGCNhnH3j22aIrkSRpcmja0AA5NNjT\nIEnSxGjq0NDebk+DJEkTpalDg4cnJEmaOIYGSZJUkaYPDY5pkCRpYjR1aHBMgyRJE6epQ4OHJyRJ\nmjhNHxo8PCFJ0sRo+tCwdSts3150JZIktb6mDg3t7Xlub4MkSeOvqUPDnDl5vmVLsXVIkjQZNHVo\nmDUrz7duLbYOSZImg6YODTNn5vm2bcXWIUnSZNDUocGeBkmSJo6hQZIkVaQlQoOHJyRJGn9NHRoG\nxjTY0yBJ0vhr6tAwY0aeGxokSRp/TR0apkzJvQ2GBkmSxl9ThwbIocExDZIkjb+mDw2zZtnTIEnS\nRDA0SJKkijR9aPDwhCRJE6PpQ4M9DZIkTQxDgyRJqkjThwYPT0iSNDGaPjTY0yBJ0sQwNEiSpIo0\nfWjw8IQkSROj6UODPQ2SJE2MlggNW7YUXYUkSa2v6UPDnDmGBkmSJkLTh4a994bNmyGloiuRJKm1\nNX1omDMH+vth+/aiK5EkqbW1RGgAeP75YuuQJKnVGRokSVJFDA2SJKkiLRMaNm8utg5Jklpd04eG\nvffOc3saJEkaX00fGjw8IUnSxDA0SJKkijR9aJg+HaZONTRIkjTemj40ROTeBkODJEnjq+lDA+TQ\n4NkTkiSNr5YIDXvvbU+DJEnjrSVCg4cnJEkafzWFhog4LyIeiohtEbE2Io4ZZd03RcSdEfFMRDwf\nEXdHxNm1l7w7D09IkjT+qg4NEfEW4HPAhcDRwL3ADRGxYIRNNgGfBF4JHAlcBlwWEa+tqeJhzJsH\nzzxTr71JkqTh1NLTsAb4WkrpypTS/cBqYCtwznArp5R+mFL6TkrpgZTSQymlLwA/Bo6vueoh5s2D\nTZvqtTdJkjScqkJDRLQBHcDNA8tSSgm4CVhV4T5OBg4F/qOa9x7NvHnw9NP12pskSRrOtCrXXwBM\nBTYMWb4BOGykjSJiLvAYMB3oB/4kpfT9Kt97RIYGSZLGX7WhYSQBpFFe3wwcBcwBTgYuiYh1KaUf\njrbTNWvW0N7ePmhZZ2cnnZ2dg5bNnw/PPgs7duSrQ0qSNBl0dXXR1dU1aFlvb++4vV/kowsVrpwP\nT2wFzkwpXVe2/HKgPaX0pgr383fA0pTSaSO8vhLo7u7uZuXKlWPu79vfhjPPhI0bc4CQJGmy6unp\noaOjA6AjpdRTz31XNaYhpdQHdJN7CwCIiCg9v7XK951ezXuPZt68PPcQhSRJ46eWwxMXA1dERDdw\nB/lsilnA5QARcSXwaErpgtLzjwB3AQ+Sg8IbgLPJZ13UxUDvwqZNsHx5vfYqSZLKVR0aUkrXlK7J\ncBGwCLgHODWl9FRplaXkwY4DZgNfLi3fBtwPvD2l9K09KbycPQ2SJI2/mgZCppQuBS4d4bWThjz/\nGPCxWt6nUoYGSZLGX0vce2LmTJg9GzYMPRFUkiTVTUuEBoBDDoFf/rLoKiRJal0tExqWL4df/KLo\nKiRJal0tExoOPdTQIEnSeGqZ0LB8OTzyCGzbVnQlkiS1ppYJDYcemuf2NkiSND5aJjQcdVS+78Tt\ntxddiSRJrallQsOcOTk43HJL0ZVIktSaWiY0ALzqVfCjHxVdhSRJramlQsNrXgMPPgg//WnRlUiS\n1HpaKjS87nX55lVXXFF0JZIktZ6WCg177QVvextcdRX094+9viRJqlxLhQaAd74T1q+HG28suhJJ\nklpLy4WGlSthxQr45jeLrkSSpNbScqEhAs44A66/HnbsKLoaSZJaR8uFBoDTT4ennoI77yy6EkmS\nWkdLhoZjj80Xe/r3fy+6EkmSWkdLhoZp0+C44+A//7PoSiRJah0tGRoAXv3qfElpxzVIklQfLRsa\njjsOnnsOHnig6EokSWoNLRsaVq7M8+7uYuuQJKlVtGxoaG+HZcsMDZIk1UvLhgbIvQ133VV0FZIk\ntYaWDg0nnAC33w6bNhVdiSRJza+lQ8OZZ8LOnfDtbxddiSRJza+lQ8OiRfCa18BXvgIpFV2NJEnN\nraVDA8D558Pdd8O3vlV0JZIkNbeWDw0nnphvYPWnfwqPPVZ0NZIkNa+WDw0AX/86TJ8Op5zioEhJ\nkmo1KULDokVw443w5JPw2tfmuSRJqs6kCA0Ahx0GN98MTzwBxx8PDz9cdEWSJDWXSRMaAF72snwT\nq507870pfvKToiuSJKl5TKrQAHDwwTk4LFq0606YkiRpbJMuNEAODD/4ARx1VL6Oww9/WHRFkiQ1\nvkkZGiDf0Oq734VXvhLe+lYHR0qSNJZJGxoAZsyAq6+G/n54xzvyWAdJkjS8SR0aAPbbD666Cr73\nPfjrvy66GkmSGtekDw2QL/r0sY/BX/yFN7eSJGkkhoaSCy+Es86Cs8+GO+8suhpJkhqPoaFkyhS4\n7LJ8RsXpp8OvflV0RZIkNRZDQ5mZM+E734FZs/KpmPffX3RFkiQ1DkPDEAsX5vtUtLXBscfCv/1b\n0RVJktQYDA3DOOQQWLs2XzHyjW+E668vuiJJkopnaBjB3Llw7bU5NLz97bBhQ9EVSZJULEPDKKZO\nhX/4hzxI8oILiq5GkqRiGRrGsGBBvobDFVfAunVFVyNJUnEMDRV4z3tg/nz4q78quhJJkopjaKjA\nrFnwoQ/l3oZHHim6GkmSimFoqNDq1Xlw5Gc+U3QlkiQVw9BQoTlz4IMfhK9/3VMwJUmTk6GhCh/4\nAJx2Wj4N80tfKroaSZImVk2hISLOi4iHImJbRKyNiGNGWffciPhhRDxdmm4cbf1G1tYG//qvcN55\nsGYN3H130RVJkjRxqg4NEfEW4HPAhcDRwL3ADRGxYIRNTgCuBk4EXgn8GvheROxXS8FFmzoVLr4Y\nli3Lt9KWJGmyqKWnYQ3wtZTSlSml+4HVwFbgnOFWTin995TSV1NKP04p/Rw4t/S+J9dadNHa2uDj\nH89jG37846KrkSRpYlQVGiKiDegAbh5YllJKwE3Aqgp3MxtoA56u5r0bzZvfDPvtB1/9atGVSJI0\nMartaVgATAWG3olhA7C4wn18BniMHDSaVlsbnHsufOMbsHlz0dVIkjT+ptVpPwGkMVeK+AhwFnBC\nSmn7WOuvWbOG9vb2Qcs6Ozvp7Oystc66eve74VOfgq6ufNVISZImUldXF11dXYOW9fb2jtv7RT66\nUOHK+fDEVuDMlNJ1ZcsvB9pTSm8aZdsPAhcAJ6eURj3vICJWAt3d3d2sXLmy4vqK8Ad/kK8S2dMD\nEUVXI0ma7Hp6eujo6ADoSCn11HPfVR2eSCn1Ad2UDWKMiCg9v3Wk7SLiQ8BHgVPHCgzNZvVquOce\nuOOOoiuRJGl81XL2xMXAeyLiHRFxOPBVYBZwOUBEXBkRnx5YOSI+DHyCfHbFIxGxqDTN3uPqG8Ap\np8CBBzogUpLU+qoODSmla4APABcBdwMvI/cgPFVaZSmDB0X+MflsiW8Bj5dNH6i97MYxdWoez/DP\n/wxPN/X5IJIkja6mK0KmlC5NKR2YUpqZUlqVUrqr7LWTUkrnlD0/KKU0dZjponp8gEZwzjnQ358H\nREqS1Kq890QdLFoEb3gD/OM/Fl2JJEnjx9BQJ+eck8+guPfeoiuRJGl8GBrq5LTTYOFCexskSa3L\n0FAnbW3wrnfBZZfBM88UXY0kSfVnaKij970P+vrgi18suhJJkurP0FBHixblS0t//vPej0KS1HoM\nDXX2oQ/B88/DxRcXXYkkSfVlaKiz/ffPhyk++1l47LGiq5EkqX4MDePgox+F2bPzXJKkVmFoGAft\n7XDRRXDFFdDdXXQ1kiTVh6FhnJx7LhxxBLz3vfmMCkmSmp2hYZxMm5av2XDPPfCJTxRdjSRJe87Q\nMI6OOQY+/nH41KfgppuKrkaSpD1jaBhnF1wAp5wCb34z/OxnRVcjSVLtDA3jbNo0+OY34aUvhde8\nxuAgSWpehoYJMHcu3HgjLFgAJ5yQ74YpSVKzMTRMkEWL4Ac/gIMPhhNPhOuvL7oiSZKqY2iYQPPm\n5QGRJ54Ib3wjfOYzkFLRVUmSVBlDwwTbe2+49to8QPIjH4Gzz873qpAkqdEZGgowZQp88pN5gOR3\nvgNHHw233150VZIkjc7QUKCzzoK7786HLV71qnzpaa8eKUlqVIaGgi1fDj/6Ub651V/+JXR0wC23\nFF2VJEm7MzQ0gLa2HBjuvBNmzoTjj4d3vQvWry+6MkmSdjE0NJCVK+HWW+ErX4FvfxsOOQTOPx+e\nfrroyiRJMjQ0nKlTYfVqWLcO3v9++OIX4aCD8niHTZuKrk6SNJkZGhrUvvvmG12tWwfnnAOf/jQs\nXZpvuX3PPUVXJ0majAwNDW7hQrjkEnjkkXzHzO99L5+i+bKX5VtuP/BA0RVKkiYLQ0OTWLgwj29Y\nty5f2+HII+Gzn4XDD4fDDsuHMm64AbZsKbpSSVKrmlZ0AarOtGlwxhl52rYtB4Xrr4d/+Rf4/Ofz\nhaNWrIBXvAKOOgoOPTRPBx2Ut5UkqVZ+jTSxmTPhD/8wTynl226vXQt33ZVP37zmmhwsIAeGgw/O\n4eGAA3aflizJgzAlSRqJoaFFRMARR+TpXe/Ky3buhMcfz+Mefv7zPP3qVzlQfOtbg0/lnDYtD7Qc\nCBEHHphDxiGH5Gnx4vwekqTJy9DQwqZMyUFg6VI4+eTdX3/++RwiBqaHH87zn/88D7gsv7jU7NmD\nQ8Qhh8CyZfnQx/775/eSJLU2Q8MkNmfOrt6J4WzZkgdePvjg4Onaa3O46O/P682YsStADJ0WLLCH\nQpJahaFBI5o9O5+lceSRu7/W37+rV6J8uvrqfHrogH32GT5MLF+eQ4skqXkYGlSTadN2HaY47bTB\nr23bBr/85e6B4rvfhY0bd623ZMnwgeKgg2CvvSb280iSxmZoUN3NnDlyD8XTT8MvfjE4TNxxB1x1\nFWzdmteZOjUHh+ECxUte4vgJSSqKoUETat48OPbYPJVLKZ/pMbR34vrr4Utf2jV+YubMfGjjwANz\nT8WSJbDffrseL1kC8+d7+qgkjQdDgxpCRO5FeMlL4Pd/f/BrfX2Dx0888EAeN7F2LTzxBDz5ZA4d\n5fuaNy8Pwpw/P8/HerzvvgYNSRqLoUENr60tn52xbBm8/vW7v97XBxs25ADx2GPw1FN57MSmTXm+\ncSP813/tev7ss7vvIyIP2iyf9t137GUDz2fN8iwRSa3P0KCm19a263oUxxwz9vr9/XlsxUCg2LQp\nB41nn4Vnnsnzgenxx3cte+YZ2L59+H1Om7YrSMyZk0NE+TR7dp7PnJnr3WuvPB+YRnq+1155mj69\nssf2lkgaT4YGTTrTpuUbgC1cWP22L7wwfLgoX7ZlSx7UuXVrfrxhw67nW7fmnpHt2/N8YNq+HXbs\n2PPPNmVK5QGj0jAyYwa0t+dpIBgNPG5vz0HIXhZpcjA0SFWYMSNfUnvx4vrve+fO3AtSHiq2bx88\nvfhi/R8/++zo62zbBs89l+sbTlvb4BAxcNhmrGkggNg7IjUPQ4PUIKZM2fXX/ezZRVczWEr5suO9\nvbt6VgYely8r73V5+OE8H+iBGSl0zJ27K0TMnVvbNHu2vR3SRDA0SBpTBOy9d56WLq1++507YfPm\nXSFiuOm553ZN69fnM2XKlw3csXU4U6bk2oaGib33zmNMBuYD09DnQ5fNmuX1QKThGBokjbspU3aN\nizjwwNr20deXg0d5kBht6u3N88cey70k5dNoAWTA7NnDh42BQa0D08yZtc2nT7d3RM3H0CCpKbS1\n5etvzJu35/vq78+DVMuDxObNu4eL4Zb19ubTe7dtywNbh85HOgwzVEQOEGOFi1qDSXm4aWvb8zaT\nwNAgaRKaNm1Xz0c9pZR7RIYLE5XOyx8//TQ8+ujI65Zf1Gw0bW27n/5bHipGWzY0wAzXyzJrVh6L\nY89J6zM0SFKdROwazLrPPuP7Xinls1tGCh7l08BpwCPNn3xy5NcqPRV4ypTKA8aeLDecFMvQIElN\nKCKPi5g+PZ99Ml4Gek6G9oLUsuzZZ0der6+v8s9dHixmzsynQg99PNyysR7PmDH4wmrlF1grXzaZ\nTxM2NEiSRjRwHY56H8oZqq9v9B6TkZYNTC+8sOvx1q35Sq9Dl5c/rnTsyXAGTo8eGi7a2vKhr6lT\nB8+HW1btvJp19967fv8uQxkaWkhXVxednZ1Fl9F0bLfq2Wa1sd1GNnAJ9blzBy8fjzZLKQ+GHRom\nXnhh94urVTofeLxjR953f/+ux6PNX3hh7PUq3dfAfPXqujbXIDWFhog4D/ggsBi4F/ifKaU7R1j3\nt4GLgA7gAOD9KaUv1FauRuMvpNrYbtWzzWpju1VvPNosYuSQ0gp6euDLXx6ffVd9+ZKIeAvwOeBC\n4GhyaLghIhaMsMks4EHgz4EnaqxTkiQVrJZrnq0BvpZSujKldD+wGtgKnDPcyimlu1JKf55SugYY\n4R6BkiSp0VUVGiKijXyY4eaBZSmlBNwErKpvaZIkqZFUO6ZhATAV2DBk+QbgsLpUlM0AuO++++q4\ny9bX29tLT09P0WU0HduterZZbWy36tlm1Sv77pxR731HqvSSYkBE7Ac8BqxKKd1etvyzwPEppePG\n2P4h4JKxBkJGxNuAf6q4MEmSNNTbU0pX13OH1fY0bAR2AIuGLF/I7r0Pe+IG4O3Aw8ALddyvJEmt\nbgZwIPm7tK6qCg0ppb6I6AZOBq4DiIgoPa/baZQppU1AXdORJEmTyK3jsdNartNwMXBFKTzcQT6b\nYhZwOUBEXAk8mlK6oPS8DfhtIIC9gJdExFHA8ymlB/f4E0iSpAlR1ZiG32wU8SfAh8mHKe4hX9zp\nrtJr3wceTimdU3p+APAQMPSN/iOldNIe1C5JkiZQTaFBkiRNPrVc3EmSJE1ChgZJklSRhgsNEXFe\nRDwUEdsiYm1EHFN0TUWJiN+LiOsi4rGI2BkRZwyzzkUR8XhEbI2IGyNi2ZDX942If4qI3oh4JiL+\nPiJmT9ynmFgRcX5E3BERz0XEhoj414g4dMg60yPiyxGxMSI2R8S3ImLhkHX2j4j/FxFbImJ9RHw2\nIhru/0u9RMTqiLi39HPSGxG3RsTryl63zcZQ+tnbGREXly2z3YaIiAtL7VQ+/azsddtsGBGxJCK+\nUWqXraWoCmkkAAAFW0lEQVT/ryuHrDPu3wcN1cg13Ayr1c0mDzQ9j90HkhIRfw78KfBe4HeBLeT2\n2qtstauBFeTTYt8AvBr42viWXajfA74IHAu8BmgDvhcRM8vW+VtyW5xJbo8lwL8MvFj65XM9+eyi\nVwLvBP4H+W6trerX5JvKdZSm7wPfiYgVpddts1GU/rh5N/l3VjnbbXg/JQ+kX1yaji97zTYbIiL2\nAW4BXgROJf9O/wDwTNk6E/N9kFJqmAlYC3y+7HkAjwIfLrq2oidgJ3DGkGWPA2vKns8FtgFnlZ6v\nKG13dNk6pwL9wOKiP9MEtduCUhscX9ZGLwJvKlvnsNI6v1t6fhrQBywoW+e9pf+g04r+TBPYdpuA\nP7LNxmynOcADwEnAvwMX+7M2antdCPSM8JptNny7/DX5jMPR1pmQ74OG6WkIb4ZVlYg4iJzQy9vr\nOeB2drXXK4FnUkp3l216E7nX4tgJKrVo+5A/79Ol5x3kv1DK2+0B4BEGt9tPUkoby/ZzA9AOHDHe\nBRctIqZExFvJ11+5DdtsLF8G/k9K6ftDlr8C220ky0uHXR+MiKsiYv/Scn/Whnc6cFdEXFM67NoT\nEecOvDiR3wcNExoY/WZYiye+nIa3mPyPPVp7LQaeLH8xpbSD/AXa8m0aEUHu6vxRSmngmOliYHvp\nP1S5oe02XLtCC7dbRPxORGwm/6V3KfmvvfuxzUZUClcvB84f5uVF2G7DWUs+nHAqsBo4CPhh6di6\nP2vDOxj4Y3KP1inAV4EvRMTZpdcn7PuglitCTrRgmOP5GlEl7TVZ2vRS8tVIjx9rRSpvk1Zut/uB\no8i9M2cCV0bEq0dZf1K3WUQsJYfS16aU+qrZlEncbiml8vsh/DQi7gB+BZzFyPcamtRtRv4D/46U\n0sdKz++NiCPIQeKqUbar+/dBI/U0TNTNsFrFevI/9mjttb70/DciYiqwLy3ephHxJeD1wIkppcfL\nXloP7BURc4dsMrTdhrbrwPOWbbeUUn9KaV1KqSel9FHyoL73YZuNpAP4LaA7Ivoiog84AXhfRGwn\nf+7pttvoUkq9wM+BZfizNpIngPuGLLsPeGnp8YR9HzRMaCgl9YGbYQGDboY1LjfeaGYppYfIPwTl\n7TWXfGxqoL1uA/aJiKPLNj2Z/MN1Oy2qFBj+APj9lNIjQ17uJg/8KW+3Q8n/+crb7cghZ+2cAvQC\nP2PymAJMxzYbyU3AkeTDE0eVprvIf/kNPO7DdhtVRMwBDiEP5PNnbXi3kAeEljuM3EMzsd8HRY8K\nHTL68yzyaM93AIeTTwXZBPxW0bUV1B6zyb98Xk4e9fr+0vP9S69/uNQ+p5N/eV0L/ALYq2wf15N/\neR0DvIp8TOwbRX+2cWyzS8mjqH+PnLoHphlD1nkIOJH81+ItwH+WvT6F/Ff2vwEvIx973QB8oujP\nN47t9inyYZwDgN8B/or8y/sk26yqdvzN2RO224ht9DfkU/0OAI4Dbix95vm22Yht9gryWKPzyQHr\nbcBm4K1l60zI90HhjTFM4/wJ8DA5PNwGvKLomgpsixPIYWHHkOkfy9b5X+SEvpU8gnjZkH3sQ/7L\np5f8Zfp3wKyiP9s4ttlw7bUDeEfZOtPJ13LYWPqP97+BhUP2sz/wf4HnS7+QPgNMKfrzjWO7/T2w\nrvT/bj3wPUqBwTarqh2/z+DQYLvt3kZd5FPpt5HPirgaOMg2G7PdXg/8uPS7/r+Ac4ZZZ9y/D7xh\nlSRJqkjDjGmQJEmNzdAgSZIqYmiQJEkVMTRIkqSKGBokSVJFDA2SJKkihgZJklQRQ4MkSaqIoUGS\nJFXE0CBJkipiaJAkSRX5/8bH2siF1Mo9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbc80ff8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets grab the predictions of our training set data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = sess.run(output_layer, feed_dict={X_init:data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a function that will give us a confusion matrix of our data and show us the F1 Score and the Total Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(pred_data, act_data, threshold=0.7):\n",
    "    stayed_true = 0\n",
    "    stayed_false = 0\n",
    "    left_true = 0\n",
    "    left_false = 0\n",
    "    for i in range(len(pred_data)):\n",
    "        if pred_data[i][0] >= threshold and act_data[i][0] == 1:\n",
    "            left_true += 1\n",
    "        elif pred_data[i][0] < threshold and act_data[i][0] == 1:\n",
    "            left_false += 1\n",
    "        elif pred_data[i][0] >= threshold and act_data[i][0] == 0:\n",
    "            stayed_false += 1\n",
    "        elif pred_data[i][0] < threshold and act_data[i][0] == 0:\n",
    "            stayed_true += 1\n",
    "    precision = left_true/np.max([1e-5, (left_true + left_false)])\n",
    "    recall = left_true/np.max([1e-5, (left_true + stayed_false)])\n",
    "    f1_score = 2*((precision*recall)/(precision+recall))\n",
    "    print(\"Stayed True: {0}\\nStayed False: {1}\\nLeft True: {2}\\nLeft False: {3}\".format(stayed_true, stayed_false, left_true, left_false))\n",
    "    print(\"Precision = {0}\".format(precision))\n",
    "    print(\"Recall = {0}\".format(recall))\n",
    "    print(\"F1 score = {0}\".format(f1_score))\n",
    "    print(\"Total Accuracy = {0}\".format((stayed_true+left_true)/(len(pred_data))) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that we have defined our function to print out the metrics that we want to see, lets test out two different thresholds for analyzing our data. We will first use the default 70% threshold that we had set in our function and then we will try a much smaller threshold, like 33%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stayed True: 9055\n",
      "Stayed False: 88\n",
      "Left True: 2542\n",
      "Left False: 315\n",
      "Precision = 0.8897444872243612\n",
      "Recall = 0.9665399239543726\n",
      "F1 score = 0.9265536723163841\n",
      "Total Accuracy = 0.9664166666666667\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(predictions, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stayed True: 8927\n",
      "Stayed False: 216\n",
      "Left True: 2638\n",
      "Left False: 219\n",
      "Precision = 0.9233461673083654\n",
      "Recall = 0.9243167484232656\n",
      "F1 score = 0.9238312029416914\n",
      "Total Accuracy = 0.96375\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(predictions, data_labels, 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, just using the threshold around 70% we get decent scores with Precision being ~89%, Recall being ~97%, F1 Score around ~93%, and Total Accuracy around ~97%. However, if we bump down the threshold to 33% we have our Precision and Recall values closer to the same value and our F1 Score and Total Accuracy dropped but only around ~0.3%. So it seems that we should use 33% as a threshold value but we will see if this is a good idea by testing with our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stayed True: 2231\n",
      "Stayed False: 54\n",
      "Left True: 669\n",
      "Left False: 45\n",
      "Precision = 0.9369747899159664\n",
      "Recall = 0.9253112033195021\n",
      "F1 score = 0.9311064718162839\n",
      "Total Accuracy = 0.9669889963321107\n"
     ]
    }
   ],
   "source": [
    "test_data = (test_set.drop(\"left\", axis=1)).values\n",
    "test_data_labels = test_set[\"left\"].values\n",
    "test_data_labels = test_data_labels.reshape([len(test_data_labels), 1])\n",
    "test_predictions = sess.run(output_layer, feed_dict={X_init:test_data})\n",
    "\n",
    "confusion_matrix(test_predictions, test_data_labels, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stayed True: 2260\n",
      "Stayed False: 25\n",
      "Left True: 642\n",
      "Left False: 72\n",
      "Precision = 0.8991596638655462\n",
      "Recall = 0.9625187406296851\n",
      "F1 score = 0.9297610427226647\n",
      "Total Accuracy = 0.9676558852950984\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(test_predictions, test_data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like, even with our test set, the 33% is a better threshold to use, to keep our Precision and Recall values close together. Now the last thing to check is to compare our cost values for the training set and test set to make sure we are not overfitting or underfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for train data: 0.10991400480270386\n",
      "Cost for test  data: 0.11098336428403854\n"
     ]
    }
   ],
   "source": [
    "print(\"Cost for train data: {0}\".format(sess.run(cost, feed_dict={X_init:data, Y_init:data_labels})) )\n",
    "print(\"Cost for test  data: {0}\".format(sess.run(cost, feed_dict={X_init:test_data, Y_init:test_data_labels}) ) )\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both cost values are around ~0.11, so it seems that we have a decent model to predict whether an employee will leave or not based on the features we look at."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
